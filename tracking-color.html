<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Document</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tracking.js/1.1.3/tracking.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/three.js/95/three.min.js"></script>
    <!-- <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script> -->

    <style>
        #video,
        #canvas {
            position: absolute;
        }

        #video {
            z-index: -1;
        }
    </style>
</head>

<body>

    <div id="app">
        <video id="video" width="800" height="600" autoplay playsinline></video>
    </div>

</body>

<script>
    class AR {

        static createCamera() {
            const constraints = window.constraints = {
                audio: false,
                video: true
            };

            const handleSuccess = (stream) => {
                const video = document.querySelector('video')
                const videoTracks = stream.getVideoTracks()
                console.log('Got stream with constraints:', constraints)
                console.log(`Using video device: ${videoTracks[0].label}`)
                window.stream = stream // make variable available to browser console
                video.srcObject = stream
            }

            const handleError = (error) => {
                if (error.name === 'ConstraintNotSatisfiedError') {
                    let v = constraints.video
                    errorMsg(
                        `The resolution ${v.width.exact}x${v.height.exact} px is not supported by your device.`
                    )
                } else if (error.name === 'PermissionDeniedError') {
                    errorMsg('Permissions have not been granted to use your camera and ' +
                        'microphone, you need to allow the page access to your devices in ' +
                        'order for the demo to work.')
                }
                errorMsg(`getUserMedia error: ${error.name}`, error)
            }

            const errorMsg = (msg, error) => {
                const errorElement = document.querySelector('#errorMsg')
                errorElement.innerHTML += `<p>${msg}</p>`
                if (typeof error !== 'undefined') {
                    console.error(error)
                }
            }

            navigator.mediaDevices
                .getUserMedia(constraints)
                .then(handleSuccess)
                .catch(handleError)
        }

        static init() {
            this.createCamera()
        }

    }

    class Track {

        static watch(cb) {
            const videoDOM = document.getElementById('video')
            const colors = new tracking.ColorTracker(['magenta', 'cyan', 'yellow'])

            colors.on('track', cb)

            tracking.track('#video', colors, {
                camera: true
            })
        }
    }

    class Draw3D {

        constructor() {
            this.scene = new THREE.Scene()
            this.camera = new THREE.PerspectiveCamera(75, 800 / 600, 0.1, 1000)
            this.renderer = new THREE.WebGLRenderer({
                alpha: true
            })
            this.init()
        }

        init() {
            const {
                scene,
                camera,
                renderer
            } = this

            camera.position.z = 500
            camera.position.x = 150
            camera.position.y = 100

            renderer.setSize(800, 600)
            document.body.appendChild(renderer.domElement)

        }

        add(mesh) {
            const { scene, renderer, camera } = this

            scene.add(mesh)

            const render = () => {
                requestAnimationFrame(render);

                mesh.rotation.x += 0.2;
                mesh.rotation.y += 0.2;
                mesh.rotation.z += 0.2;

                renderer.render(scene, camera);
            }

            render()
        }
    }

    window.onload = () => {

        AR.init()

        const my3D = new Draw3D()

        Track.watch((e) => {
            if (e.data.length) {

                const { width, height, x, y} = e.data[0]

                const geometry = new THREE.BoxBufferGeometry(80, 80, 80)
                const material = new THREE.MeshNormalMaterial()
                const mesh = new THREE.Mesh(geometry, material)

                  mesh.position.x = x
                  mesh.position.y = y

                my3D.add(mesh)
            }
        })
    }
</script>

</html>